{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eye-Crop.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5gV+utANDyHDI6UoLag0z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotiprajapati98/Image-Processing/blob/main/Eye_Crop_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXMKsj9M2_tV"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "import os\n",
        "import math\n"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TrvNyBL3aDq"
      },
      "source": [
        "def stackImages(scale, imgArray):\n",
        "    rows = len(imgArray)\n",
        "    cols = len(imgArray[0])\n",
        "    rowsAvailable = isinstance(imgArray[0], list)\n",
        "    width = imgArray[0][0].shape[1]\n",
        "    height = imgArray[0][0].shape[0]\n",
        "    if rowsAvailable:\n",
        "        for x in range(0, rows):\n",
        "            for y in range(0, cols):\n",
        "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape[:2]:\n",
        "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
        "                else:\n",
        "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]),\n",
        "                                                None, scale, scale)\n",
        "                if len(imgArray[x][y].shape) == 2: imgArray[x][y] = cv2.cvtColor(imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
        "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
        "        hor = [imageBlank] * rows\n",
        "        hor_con = [imageBlank] * rows\n",
        "        for x in range(0, rows):\n",
        "            hor[x] = np.hstack(imgArray[x])\n",
        "        ver = np.vstack(hor)\n",
        "    else:\n",
        "        for x in range(0, rows):\n",
        "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
        "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
        "            else:\n",
        "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None, scale, scale)\n",
        "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
        "        hor = np.hstack(imgArray)\n",
        "        ver = hor\n",
        "    return ver\n"
      ],
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfACync3swi"
      },
      "source": [
        "def hisEqulColor(img):\n",
        "    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
        "    channels = cv2.split(ycrcb)\n",
        "    # print (len(channels))\n",
        "    cv2.equalizeHist(channels[0], channels[0])\n",
        "    cv2.merge(channels, ycrcb)\n",
        "    cv2.cvtColor(ycrcb, cv2.COLOR_YCR_CB2BGR, img)\n",
        "    return img\n",
        "\n",
        "\n",
        "def reduce_size_of_image(img):\n",
        "    height, width = img.shape[:2]\n",
        "    eyebrow_h = int(height / 1.5)  # Can be made ~25% by putting 4 in place of 3\n",
        "    width_left = int(width / 6)\n",
        "    width_right = int(width / 6)\n",
        "    # img = img[eyebrow_h:height, 0:width]  # cut eyebrows out (15 px)\n",
        "    img = img[eyebrow_h:height, width_left:(width - width_right)]\n",
        "    return img\n",
        "\n",
        "\n",
        "def reduce_size_of_image_after_centroid_detection(img, cX):\n",
        "    height, width = img.shape[:2]\n",
        "    width_left = int(width / 6)\n",
        "    width_right = int(width / 6)\n",
        "    img = img[cX:height, width_left:(width - width_right)]\n",
        "    return img\n",
        "\n",
        "\n",
        "def auto_canny(image1, sigma=0.55):\n",
        "    # compute the median of the single channel pixel intensities\n",
        "    image = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
        "    v = np.median(image)\n",
        "    # apply automatic Canny edge detection using the computed median\n",
        "    lower = int(max(0, (1.0 - sigma) * v))\n",
        "    upper = int(min(255, (1.0 + sigma) * v))\n",
        "    edged = cv2.Canny(image, lower, upper)\n",
        "    # return the edged image\n",
        "    return edged\n",
        "\n",
        "\n",
        "def MODIFICATION(path_init):\n",
        "    def Modification_sub(dist, path_init):\n",
        "        if dist == 'F':\n",
        "            dis = 25  # 25\n",
        "        else:\n",
        "            dis = 25\n",
        "        eye1 = cv2.imread(path_init)\n",
        "        eye = eye1\n"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SB9i-cx6DcE"
      },
      "source": [
        "def ImfillPython(im_in):\n",
        "            im_in = cv2.imread(\"My Image1.png\", cv2.IMREAD_GRAYSCALE)\n",
        "            # Threshold.\n",
        "            # Set values equal to or above 220 to 0.\n",
        "            # Set values below 220 to 255.\n",
        "            th, im_th = cv2.threshold(im_in, 50, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "            # Copy the thresholded image.\n",
        "            im_floodfill = im_th.copy()\n",
        "\n",
        "            # Mask used to flood filling.\n",
        "            # Notice the size needs to be 2 pixels than the image.\n",
        "            h, w = im_th.shape[:2]\n",
        "            mask = np.zeros((h + 2, w + 2), np.uint8)\n",
        "\n",
        "            # Floodfill from point (0, 0)\n",
        "            cv2.floodFill(im_floodfill, mask, (0, 0), 255)\n",
        "\n",
        "            # Invert floodfilled image\n",
        "            im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
        "\n",
        "            # Combine the two images to get the foreground.\n",
        "            im_out = im_th | im_floodfill_inv\n",
        "\n",
        "            # Display images.\n",
        "            path1 = 'Foreground.png'\n",
        "            cv2.imwrite(path1, im_out)\n",
        "\n",
        "            img_new = Image.open(path1)\n",
        "            img_inverted = PIL.ImageOps.invert(img_new)\n",
        "            imfill_path = 'Imfill.png'\n",
        "            img_inverted.save(imfill_path)\n",
        "            return imfill_path\n"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN-HxkxB6Gp6"
      },
      "source": [
        "detector_params = cv2.SimpleBlobDetector_Params()\n",
        "detector_params.filterByArea = True\n",
        "detector_params.maxArea = 1500  # 1500\n",
        "detector = cv2.SimpleBlobDetector_create(detector_params)\n"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boOolZiZ6is3",
        "outputId": "6e231501-01ce-494e-adee-645add618b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        " def cut_eyebrows(img):\n",
        "            height, width = img.shape[:2]\n",
        "            eyebrow_h = int(height / 4)\n",
        "            img = img[eyebrow_h:height, 0:width]  # cut eyebrows out (15 px)\n",
        "            return img\n",
        "\n",
        "            eye = cut_eyebrows(eye)\n",
        "            cv2.imshow('my image', eye)\n",
        "\n",
        "        # cv2.imwrite(\"eye1.png\",eye)\n",
        "        # cv2.waitKey(0)\n",
        "\n",
        " def Refine(input_path):\n",
        "            img_init = cv2.imread(input_path)\n",
        "            img = Image.open(input_path)\n",
        "            rows, columns = img_init.shape[0], img_init.shape[1]\n",
        "            limit = int(0.28 * columns)\n",
        "            pix = img.load()\n",
        "            for i in reversed(range(0, rows)):\n",
        "                for j in reversed(range(columns - limit, columns)):\n",
        "                    pix[j, i] = (255, 255, 255)\n",
        "\n",
        "            result_path = 'Final Blob.png'\n",
        "            img.save(result_path)\n",
        "            return result_path\n",
        " def blob_process(img, detector):\n",
        "            gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            _, img = cv2.threshold(gray_frame, 35, 255, cv2.THRESH_BINARY)  # 30\n",
        "\n",
        "            cv2.imwrite(\"My Image1.png\", img)\n",
        "\n",
        "            path_req = ImfillPython(img)\n",
        "            img = cv2.imread(path_req)\n",
        "\n",
        "            kernel = np.ones((5, 5), np.uint8)\n",
        "            img = cv2.erode(img, kernel, iterations=2)  # 1\n",
        "            img = cv2.dilate(img, kernel, iterations=6)  # 2\n",
        "            img = cv2.medianBlur(img, 5)  # 3\n",
        "\n",
        "            cv2.imwrite(\"my image3.png\", img)\n",
        "\n",
        "            keypoints = detector.detect(img)\n",
        "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            ret, thresh = cv2.threshold(gray_image, 127, 255, 0)\n",
        "\n",
        "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "            count = 0\n",
        "            if len(contours) == 0:\n",
        "                return False\n",
        "            for c in contours:\n",
        "                if count == len(contours) - 1 and len(contours) > 1:\n",
        "                    # calculate moments for each contour\n",
        "                    M = cv2.moments(c)\n",
        "                    # calculate x,y coordinate of center\n",
        "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "                    # print(cX, cY)\n",
        "                    cx_fin = cX\n",
        "                    cy_fin = cY\n",
        "                    cv2.circle(eye, (cX, cY), 3, (255, 0, 0), -1)\n",
        "                    new_cx, new_cy = cX, cY + dis\n",
        "                    # cv2.circle(eye, (new_cx, new_cy), 3, (0, 255, 0), -1)        #Uncomment this for display purpose\n",
        "                    # cv2.imshow(\"!\", eye)\n",
        "                    # cv2.waitKey(0)\n",
        "                    img_my = reduce_size_of_image_after_centroid_detection(eye, new_cy)\n",
        "                    ROI_reduced_path = \"ROI_Reduced.jpg\"\n",
        "                    cv2.imwrite(ROI_reduced_path, img_my)\n",
        "                    break\n",
        "                elif len(contours) == 1:\n",
        "                    # calculate moments for each contour\n",
        "                    M = cv2.moments(c)\n",
        "                    # calculate x,y coordinate of center\n",
        "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
        "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
        "                    # print(cX, cY)\n",
        "                    cx_fin = cX\n",
        "                    cy_fin = cY\n",
        "                    cv2.circle(eye, (cX, cY), 3, (255, 0, 0), -1)\n",
        "                    new_cx, new_cy = cX, cY + dis\n",
        "                    # cv2.circle(eye, (new_cx, new_cy), 3, (0, 255, 0), -1)       #Uncomment this for display purpose\n",
        "                    # cv2.imshow(\"!\", eye)\n",
        "                    # cv2.waitKey(0)\n",
        "                    img_my = reduce_size_of_image_after_centroid_detection(eye, new_cy)\n",
        "                    ROI_reduced_path = \"ROI_Reduced.jpg\"\n",
        "                    cv2.imwrite(ROI_reduced_path, img_my)\n",
        "                else:\n",
        "                    count += 1\n",
        "\n",
        "            return keypoints, cx_fin, cy_fin, img_my\n",
        "\n",
        "            if not blob_process(eye, detector):\n",
        "                    # print(\"\\nUnclear Image or Blob Not Detected. Please Capture New Image!!\")\n",
        "                    return False, 0\n",
        "\n",
        "            keypoints, cx_fin, cy_fin, img_my = blob_process(eye, detector)\n",
        "\n",
        "        # eye = cv2.drawKeypoints(eye, keypoints, eye, (0, 255, 0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "        # cv2.destroyAllWindows()\n",
        "        # cv2.imshow('Result1', eye)\n",
        "        # cv2.waitKey(0)\n",
        "        # cv2.imshow('Result2', img_my)\n",
        "        # cv2.waitKey(0)\n",
        "        # cv2.destroyAllWindows()\n",
        "\n",
        "            Modification_sub('F', path_init)\n",
        "            return True\n",
        "\n",
        "def Eye_Detection(img):\n",
        "    eyesCascade = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_eye.xml\")\n",
        "    eyes = eyesCascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=4, minSize=(100, 100))\n",
        "\n",
        "    if len(eyes) != 0:\n",
        "        print(\"Number of Eyes detected = \", len(eyes))\n",
        "        for (x, y, w, h) in eyes:\n",
        "            eye = img[y:y + h, x:x + w]\n",
        "            ROI = eye\n",
        "            cv2.imwrite(\"ROI_1.jpg\", ROI)\n",
        "\n",
        "            ROI_reduced = cv2.imread('ROI_1.jpg')\n",
        "            # Use the MODIFICATION function here; If blob is detected then use the modified reduced image; If blob is\n",
        "            # not identified, return False and reduce the image by the previous method; However if blob is detected\n",
        "            # in a wrong position and detected centroid is different then we need to check that manually; A solution\n",
        "            # to the above problem is to display the Reduced Image and computer asks whether user is satisfied with\n",
        "            # the capture; If user says YES(Y), the rest of the work takes place; If user says NO(N), the code stops\n",
        "            # and prompts the user to take a better image;\n",
        "\n",
        "            path_init = 'ROI_1.jpg'\n",
        "            boolean = MODIFICATION(path_init)\n",
        "            if not boolean:\n",
        "                ROI_reduced = reduce_size_of_image(ROI_reduced)\n",
        "                ROI_reduced_path = \"ROI_Reduced.jpg\"\n",
        "                cv2.imwrite(ROI_reduced_path, ROI_reduced)\n",
        "\n",
        "            check_img = cv2.imread('ROI_Reduced.jpg')\n",
        "            cv2.imshow(\"Reduced Image\", check_img)\n",
        "            cv2.waitKey(0)\n",
        "            satisfaction = str(input('Are you satisfied with the Reduced Image [Y/N]? '))\n",
        "            satisfaction = satisfaction.upper()\n",
        "\n",
        "            if satisfaction != 'Y':\n",
        "                return 129, 129\n",
        "\n",
        "            ROI_reduced_path = 'ROI_Reduced.jpg'\n",
        "            ROI_reduced_1_color = cv2.imread('ROI_Reduced.jpg')\n",
        "            # ROI_reduced_1 = cv2.cvtColor(ROI_reduced_1_color, cv2.COLOR_BGR2GRAY)\n",
        "            # ROI_reduced_1_color_median = cv2.medianBlur(ROI_reduced_1_color, 1)\n",
        "            edges = auto_canny(ROI_reduced_1_color)\n",
        "            # ROI_reduced_1_blurred = cv2.GaussianBlur(ROI_reduced_1_color_median, (5, 5), 0)\n",
        "            # edges = cv2.Canny(ROI_reduced_1_blurred, 40, 150)  # Originally was 30, 150\n",
        "\n",
        "            edges_path = \"EDGES.png\"\n",
        "            cv2.imwrite(edges_path, edges)\n",
        "\n",
        "            # imgStack = stackImages(0.5, ([ROI, ROI_reduced, edges]))\n",
        "            # cv2.imshow(\"Stacked Images\", imgStack)  ## Uncomment this\n",
        "            # cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "            return ROI_reduced_path, edges_path\n",
        "    else:\n",
        "        return 0, 0\n",
        "\n",
        "\n",
        "def Get_Conjunctiva_Region(ROI_reduced_path, edges_path):\n",
        "    img_init = cv2.imread(edges_path)\n",
        "    img = Image.open(edges_path)\n",
        "    rows, columns = img_init.shape[0], img_init.shape[1]\n",
        "\n",
        "    pix = img.load()\n",
        "\n",
        "    for i in range(0, rows):\n",
        "        for j in range(0, columns):\n",
        "            # print(pix[j, i])\n",
        "            if pix[j, i] > 250:\n",
        "                for k in range(0, i):\n",
        "                    pix[j, k] = 255\n",
        "\n",
        "    inverted_image = PIL.ImageOps.invert(img)\n",
        "    inverted_image.save('EdgesTest.png')\n",
        "\n",
        "    img_red = cv2.imread(ROI_reduced_path)\n",
        "    img_new = cv2.imread('EdgesTest.png')\n",
        "\n",
        "    fin_img = cv2.subtract(img_red, img_new)\n",
        "\n",
        "    result_path = \"RESULT.jpg\"\n",
        "    for i in range(len(fin_img)):\n",
        "        for j in range(len(fin_img[i])):\n",
        "            img_val_list = [fin_img[i][j]]\n",
        "            if img_val_list[0][0] < 10 and img_val_list[0][1] < 10 and img_val_list[0][2] < 10:\n",
        "                fin_img[i][j] = [255, 255, 255]  # _val_list = [[255,255,255]]\n",
        "\n",
        "    # cv2.imshow('FINAL ROI', fin_img)\n",
        "    # cv2.waitKey(0)\n",
        "    cv2.imwrite(result_path, fin_img)\n",
        "    cv2.destroyAllWindows()\n",
        "    return result_path\n",
        "\n",
        "\n",
        "img = cv2.imread(\"51.png\")\n",
        "ROI_reduced_path, edges_path = Eye_Detection(img)\n",
        "if ROI_reduced_path == 129 and edges_path == 129:\n",
        "    print(\"\\nPlease Capture a New Image!!\")\n",
        "elif ROI_reduced_path == 0 and edges_path == 0:\n",
        "    print(\"\\nNo eyes detected!!\")\n",
        "else:\n",
        "    result_path = Get_Conjunctiva_Region(ROI_reduced_path, edges_path)\n",
        "    img_res = cv2.imread(result_path)\n",
        "    imgStack = stackImages(0.5, ([img, img_res]))\n",
        "    # cv2.imshow(\"Stacked Images\", imgStack)    # For showing results to Profs\n",
        "    # cv2.waitKey(0)\n",
        "\n",
        "os.remove('EDGES.png')\n",
        "os.remove('EdgesTest.png')\n",
        "os.remove('Foreground.png')\n",
        "os.remove('Imfill.png')\n",
        "os.remove('My Image1.png')\n",
        "os.remove('my image3.png')\n",
        "os.remove('ROI_Reduced.jpg')\n",
        "os.remove('ROI_1.jpg')\n",
        "\n",
        "add_value = 3\n",
        "# opencv loads the image in BGR, convert it to RGB\n",
        "img_orig = cv2.imread('RESULT.jpg')\n",
        "startIdx = []\n",
        "endIdx = []\n",
        "whitebeginIdx = []\n",
        "for row in range(len(img_orig)):\n",
        "    for column in range(len(img_orig[0])):\n",
        "        if img_orig[row][column][0] < 220 and img_orig[row][column][1] < 220 and img_orig[row][column][2] < 220:\n",
        "            startIdx.append([row, column])\n",
        "            break\n",
        "    break\n",
        "\n",
        "for row in range(len(img_orig)):\n",
        "    for column in reversed(range(len(img_orig[0]))):\n",
        "        if img_orig[row][column][0] < 220 and img_orig[row][column][1] < 220 and img_orig[row][column][2] < 220:\n",
        "            endIdx.append([row, column])\n",
        "            break\n",
        "    break\n",
        "\n",
        "mid_point = (startIdx[0][1] + endIdx[0][1]) // 2\n",
        "\n",
        "for row in range(0, len(img_orig)):\n",
        "    if img_orig[row][mid_point][0] > 230 and img_orig[row][mid_point][1] > 230 and img_orig[row][mid_point][2] > 230:\n",
        "        whitebeginIdx.append(row)\n",
        "        break\n",
        "\n",
        "if 60 <= len(img_orig) < 100:\n",
        "    my_value = 23\n",
        "elif len(img_orig) >= 90:\n",
        "    my_value = 40\n",
        "else:\n",
        "    my_value = 18\n",
        "\n",
        "y_coordinate = whitebeginIdx[0] - my_value\n",
        "\n",
        "img1 = cv2.rectangle(img_orig, (mid_point, y_coordinate), (mid_point + 5, y_coordinate + 5), (0, 255, 255), 1)\n",
        "img2 = img_orig[y_coordinate:y_coordinate + 5, mid_point:mid_point + 5]\n",
        "img = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "img4 = cv2.rectangle(img_orig, (mid_point + 10, y_coordinate), (mid_point + 5 + 10, y_coordinate + 5), (0, 255, 255), 1)\n",
        "img5 = cv2.rectangle(img_orig, (mid_point - 10, y_coordinate), (mid_point + 5 - 10, y_coordinate + 5), (0, 255, 255), 1)\n",
        "\n",
        "# cv2.imshow(\"F1\", img5)\n",
        "# cv2.waitKey(0)\n",
        "\n",
        "img8 = img_orig[y_coordinate:y_coordinate + 5, mid_point + 10:mid_point + 5 + 10]\n",
        "img9 = img_orig[y_coordinate:y_coordinate + 5, mid_point - 10:mid_point + 5 - 10]\n",
        "\n",
        "img11 = cv2.cvtColor(img8, cv2.COLOR_BGR2RGB)\n",
        "img12 = cv2.cvtColor(img9, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "############################################################################\n",
        "red_list = []\n",
        "green_list = []\n",
        "blue_list = []\n",
        "\n",
        "#############################################################################\n",
        "# 1st small patch\n",
        "histg_list = []\n",
        "histr_list = []\n",
        "\n",
        "histg = cv2.calcHist([img], [1], None, [256], [0, 220])\n",
        "histr = cv2.calcHist([img], [0], None, [256], [0, 220])\n",
        "histb = cv2.calcHist([img], [2], None, [256], [0, 220])\n",
        "\n",
        "total_value_g = 0\n",
        "for i in range(len(histg)):\n",
        "    total_value_g += (i * histg[i])\n",
        "avg_value_g = total_value_g / sum(histg)\n",
        "\n",
        "total_value_r = 0\n",
        "for i in range(len(histr)):\n",
        "    total_value_r += (i * histr[i])\n",
        "avg_value_r = total_value_r / sum(histr)\n",
        "\n",
        "total_value_b = 0\n",
        "for i in range(len(histb)):\n",
        "    total_value_b += (i * histb[i])\n",
        "avg_value_b = total_value_b / sum(histb)\n",
        "red_list.append(avg_value_r)\n",
        "blue_list.append(avg_value_b)\n",
        "green_list.append(avg_value_g)\n",
        "\n",
        "##########################################################33\n",
        "# 2nd Small patch\n",
        "histg_list = []\n",
        "histr_list = []\n",
        "\n",
        "histg = cv2.calcHist([img11], [1], None, [256], [0, 220])\n",
        "histr = cv2.calcHist([img11], [0], None, [256], [0, 220])\n",
        "histb = cv2.calcHist([img11], [2], None, [256], [0, 220])\n",
        "\n",
        "total_value_g = 0\n",
        "for i in range(len(histg)):\n",
        "    total_value_g += (i * histg[i])\n",
        "avg_value_g = total_value_g / sum(histg)\n",
        "\n",
        "total_value_r = 0\n",
        "for i in range(len(histr)):\n",
        "    total_value_r += (i * histr[i])\n",
        "avg_value_r = total_value_r / sum(histr)\n",
        "\n",
        "total_value_b = 0\n",
        "for i in range(len(histb)):\n",
        "    total_value_b += (i * histb[i])\n",
        "avg_value_b = total_value_b / sum(histb)\n",
        "red_list.append(avg_value_r)\n",
        "blue_list.append(avg_value_b)\n",
        "green_list.append(avg_value_g)\n",
        "\n",
        "###############################################################\n",
        "# 3rd small patch\n",
        "histg_list = []\n",
        "histr_list = []\n",
        "\n",
        "histg = cv2.calcHist([img12], [1], None, [256], [0, 220])\n",
        "histr = cv2.calcHist([img12], [0], None, [256], [0, 220])\n",
        "histb = cv2.calcHist([img12], [2], None, [256], [0, 220])\n",
        "\n",
        "total_value_g = 0\n",
        "for i in range(len(histg)):\n",
        "    total_value_g += (i * histg[i])\n",
        "avg_value_g = total_value_g / sum(histg)\n",
        "\n",
        "total_value_r = 0\n",
        "for i in range(len(histr)):\n",
        "    total_value_r += (i * histr[i])\n",
        "avg_value_r = total_value_r / sum(histr)\n",
        "\n",
        "total_value_b = 0\n",
        "for i in range(len(histb)):\n",
        "    total_value_b += (i * histb[i])\n",
        "avg_value_b = total_value_b / sum(histb)\n",
        "\n",
        "red_list.append(avg_value_r)\n",
        "blue_list.append(avg_value_b)\n",
        "green_list.append(avg_value_g)\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "avg_value_r = sum(red_list) / 3\n",
        "avg_value_b = sum(blue_list) / 3\n",
        "avg_value_g = sum(green_list) / 3\n",
        "\n",
        "val1 = (-1.922 + 0.206 * avg_value_r - 0.241 * avg_value_g + 0.012 * avg_value_b)\n",
        "Num = math.exp(val1)\n",
        "Den = 1 + math.exp(val1)\n",
        "L = Num / Den\n",
        "if (L * 10 + add_value) < 6:\n",
        "    Hgb_val = 10\n",
        "else:\n",
        "    Hgb_val = (L * 10 + add_value)\n",
        "print(\"\\n Hgb = \", round(Hgb_val, 2), \"g/dl\")\n",
        "\n",
        "if Hgb_val < 13:  # A Threshold value I have used on the basis of data available to me\n",
        "    print(\"\\nAnemic\")\n",
        "else:\n",
        "    print(\"\\nNon-Anemic\")\n",
        "\n",
        "startIdx = []\n",
        "endIdx = []\n",
        "whitebeginIdx = []\n",
        "\n"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "No eyes detected!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-287-3de46584b4f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m    \u001b[0;31m# cv2.waitKey(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EDGES.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EdgesTest.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Foreground.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EDGES.png'"
          ]
        }
      ]
    }
  ]
}